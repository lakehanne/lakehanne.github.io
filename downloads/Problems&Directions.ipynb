{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e50bff5-9f4b-4e09-af36-1d21fadebfb3",
   "metadata": {},
   "source": [
    "## Open Problems in Cyber Physical Systems\n",
    "### [What is Stability?](#Stability)\n",
    "### [What is Safety?](#Safety)\n",
    "#### [Barrier Functions](#Control-Barrier-Functions)\n",
    "##### [Safe Sets, and Invariance](#Safe-Sets-and-Invariance)\n",
    "#### [Hamilton-Jacobi Reachability](#Reachability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8341fe-10d3-47d1-b707-08faf110da2f",
   "metadata": {},
   "source": [
    "##  Open Problems in Cyber Physical Systems\n",
    "\n",
    "Safety and stability are critical issues for autonomous systems -- and cyber-physical systems [CPS] in particular in the 21st century. Broad open research themes in CPS includes:\n",
    "\n",
    "+ developing data-driven control algorithms based on deep reinforcement learning designed to enable control in settings where analytical approaches to derive explicit controllers are too complex (e.g., due to multi-lane, ramps, and high variation of human driving styles). \n",
    "\n",
    "   - See Penn NSF project 1837210  (PI: George Pappas, Lekan's mentor :) )\n",
    "   \n",
    "   - George has a research thrust on tools based on Satisfiability Modulo Convex optimization to enable safety and robustness of these controllers\n",
    "   \n",
    "+ rethinking communication and control for low-latency, high reliability IoT devices (e.g. see Penn's NSF CPS project 1837253).\n",
    "\n",
    "    - rethinking the scientific foundations for ultra-reliable, low-latency wireless communications for latency sensitive control applications\n",
    "    \n",
    "    - control over low latency-aware communication channels, where the goal is to understand the what is the optimal tradeoff of latency to reliability for control loops \n",
    "    \n",
    "    - learning for Large Scale Wireless Control Networks, where machine learning will perform resource allocation for large numbers of control loops with competing latency/reliability requirements\n",
    "    \n",
    "+  analysis tools for non-smooth switched and hybrid systems that account for various switching triggers and uncertainty. For complex nonlinear systems, design is inspired from analysis. How to develop adaptive and optimal design tools that are integrated with high-level logic-based control synthesis tools in Adaptation, Optimality, and Synthesis?   \n",
    "\n",
    "The above are just examples from my interations with George in my time at Penn.There are other areas that the broader community is focussing on viz.,\n",
    "\n",
    "In self-driving of cars, adaptive cruise control on highways, allocation problems in multidimensional systems, it is often not enough to rely on asymptotic stability (or relaxed stability i.e. stabilization) guarantees of an equilibrium point; we generally want the system to return to the equilibrium points with a $\\pm \\epsilon$ tolerance that guarantees the robustness of the equilibrium e.g. under a worst-case disturbance. In this light, there are two interesting themes, drawing inspiration from \n",
    "\n",
    "+ nonlinear control theory and;\n",
    "+ optimality in Hamilton-Jacobi-Isaacs variational inequality problems\n",
    "\n",
    "that researchers have leveraged to provide stability and safety guarantees for problems.  If you are familiar with basic control theory using differential equations, you may skip the next two definitions.\n",
    "\n",
    "\n",
    "### Stability\n",
    "\n",
    "Here, I give a layman's treatment of stability just to set us all on an equal footing during meetings and improve the quality of our discussions.\n",
    "\n",
    "Stability is generally considered to be deviation about some fixed motion. Formally, stability from the _second method of Lyapunov_ attempts to answer questions of the stability of **differential equations** utilizing the given form of the equations but without an explicit knowledge of the solutions. Most of the theory of control systems can be unifiedly studied with Lyapunov functions. \n",
    "Define an autonomous dynamical system as\n",
    "\n",
    "\\begin{align}\n",
    "    \\dot{x}(u(t); t) = f(x(t), u(t); t)    \\label{eq:dyna}\n",
    "\\end{align}\n",
    "\n",
    "where the semi-colon implies that the dynamics may implicitly (whereupon it is time-invariant) or explicitly (time-varying) depend on time, $t$. If $u=0$ above, we say the system is _non-autonomous or free_. Most physical system exhibit affine dynamics i.e. the control law enters explicitly into the dynamical system as follows (abusing notation and dropping the templated arguments):\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "    \\dot{x}(u; t) = f(x, u; t)  + g(x; t) u.  \\label{eq:affine}\n",
    "\\end{align}\n",
    "\n",
    "An example could be the bicyle model, where in the simplest dynamics model, we have the steering angle of the bike ($\\delta$) being influenced by both the steering torque ($T$) and the tilt of the frame $\\theta$. A bike with a front fork is an example of a _feedback system_, where the control law e.g. for the steering angle of the fork (of the front wheel), has a direct effect on the tilt of the bicycle. Here, the tilt state ($\\theta$) of the bike influences the steering angle ($\\delta$), and the steering angle, $\\delta$, influences the tilt angle, $\\theta$, giving rise to the so-called **circular causality**. As such, in most control design -- at least for autonomous systems -- control affine dynamics such as the one we've written above are typical.\n",
    "\n",
    "The principal idea of the second method of Lyapunov is in the following physical reasoning: **If the rate of change $dV(x)/dt$ of the energy $V(x)$ of an isolated physical system is negative for every possible state $x$, except for a single equilibrium state $x_e$ then the energy will continually decrease until it finally assumes its minimum value $E(x_e)$**. In control theory literature, $V(x)$ is generally referred to as the Lyapunov function. \n",
    "In other words, a dissipative system perturbed from its equilibrium state will always return to it; this is the intuitive concept of stability [Kalman & Bertram, 1960]. More formally, an equilibrium state \\\\(x_e\\\\) of a free dynamic system  is _**stable**_ i.e. for every real number \\\\(\\epsilon>0\\\\), there exists a real number \\\\(\\delta(\\epsilon, t_0)>0\\\\) such that \\\\(\\|x_0 - x_e\\| \\le \\delta \\\\) implies\n",
    "\n",
    "\\begin{align}\n",
    "  ||\\Phi(t; x_0, t_0) - x_e|| \\le \\epsilon \\quad \\forall \\quad t \\ge t_0 \\nonumber\n",
    "\\end{align}\n",
    "\n",
    "Read: $\\Phi(\\cdot)$ is the solution to the o.d.e for an initial state $x(0) = x_0$ that starts at time $t(0) = t_0$ and observed at time $t$ (e.g. secs later). In this light, different notions of stability have been posited in the literature over the years but below are simple guides for stability and the formula above:\n",
    "\n",
    "\n",
    "Lyapunov Stability             |  Asymptotic Stability     |  Stability  Relations\n",
    ":-------------------------:|:-------------------------:|:-------------------------:\n",
    "<img src=\"http://scriptedonachip.com/assets/control/stability.png\" alt=\"equilibrium\" width=\"400\" height=\"400\" />  |  <img src=\"http://scriptedonachip.com/assets/control/asymptotic_stability.png\" alt=\"equilibrium\" width=\"400\" height=\"400\" /> | <img src=\"http://scriptedonachip.com/assets/control/control_concepts.png\" alt=\"equilibrium\" width=\"1000\" height=\"1000\" /> \n",
    "\n",
    "Reprinted from [Kalman and Bertram, 1960].\n",
    "\n",
    "There are foundational texts on nonlinear control and the second method of Lyapunov. Authoritative texts that I highly recommend include:\n",
    "\n",
    "+ Kalman, Rudolf E., and John E. Bertram. \"[Control system analysis and design via the “second method” of Lyapunov: I—continuous-time systems.](https://scholar.google.com/scholar_url?url=https://www.academia.edu/download/47670548/Control_System_Analysis_and_Design_Via_the_Second_Method_of_Lyapunov-I.pdf&hl=en&sa=T&oi=gsb-gga&ct=res&cd=0&d=18209321835022209097&ei=--nxYMb-OvGAy9YPoYy3sAQ&scisig=AAGBfm04-suO1qRd-tfuVq8rZ5wwSV9tdw)\" (1960): 371-393.\n",
    "\n",
    "+ Khalil, Hasan. [Nonlinear Systems](https://www.amazon.com/Nonlinear-Systems-3rd-Hassan-Khalil/dp/0130673897).\n",
    "\n",
    "\n",
    "## Safety\n",
    "\n",
    "                                                                                         \n",
    "\n",
    "Despite the existence and uniquesness theorems that we've seen in control stability analysis and synthesis over the past 60 years, open problems remain, especially in cyber-physical systems. Here, one must not only design a control law or class of control laws that satisfy performance objective [See Sontag, 1983; Atrstein 1979], but also assure that these conflicting objectives do not discombobulate the closed-loop system (the loop of a dynamical system becomes closed-loop when we find a feedback stabilizing law that guarantees asymptotic stability for all states). What we notice often is that as the scaling of systems increase in the constraints we want to satisfy with our controllers, potentially conflicting objectives ensue. \n",
    "\n",
    "How do we create a formal means for designing safety-critical systems where there exists tight coupling between control performance specifications and safety constraints? There are two major schools of thought:\n",
    "\n",
    "+ Control Barrier FunctionsL: Express safety conditions as _control barrier functions (CBFs)_, to be unified with performance objectives -- expressed as control Lyapunov functions -- in the context of real-time optimization Lyapunov functions;\n",
    "\n",
    "+ HJ Reachability: Express safety conditions as a reachability concept -- leverage Hamilton-Jacobi-Isaacs (HJI) equation in solving a variational inequality  that allows us to generate a robustly controlled backward reachable tube (or backward reach-avoid-tube) -- this gives us a concept of safe and unsafe set of control laws that are valid for a given dynamical system.\n",
    "\n",
    "\n",
    "And these problems have many questions remain unsettled. While Lyapunov functions assume local Lipschitz continuity in the state $x$ and piecewise continuity in time $t$, most physical systems do not give an engineer the luxury of prescribing entirely continuous differential equations or discrete difference equations for formulating the dynamics. In computer science, exoskeletons, humanoids and etc, the dynamics is usually a mixture of discrete and continuous states. As such, the differential equations we end up with are typically [Fillipov in nature i.e. differential equations with discontinuous right hand sides](https://www.springer.com/gp/book/9789027726995). This means the fundamental assumptions about the o.d.e needs be revisited.\n",
    "\n",
    "\n",
    "\n",
    "Even so, there are critical systems that operate in the real-world, whose dynamics are not necessarily known. With the advent of deep learning and their effectiveness at nonparametric approximation of underlying system dynamics (e.g. differential equations and difference equations), it behooves us to rethink finding CBFs or CLFs for a system from a learning perspective. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6eba83-681d-403f-9e16-08dca0635844",
   "metadata": {},
   "source": [
    "#### **Control Barrier Functions**\n",
    "\n",
    "For the nonlinear control affine function,\n",
    "\n",
    "\\begin{align}\n",
    "    \\dot{\\boldsymbol{x}} = \\boldsymbol{f}(\\boldsymbol{x}) + \\boldsymbol{g}(\\boldsymbol{x})\\boldsymbol{u}\n",
    "    \\label{eq:cbfs::control_affine}\n",
    "\\end{align}\n",
    "\n",
    "where \\\\(\\boldsymbol{x} \\in \\mathbb{R}^n\\\\), \\\\(\\boldsymbol{u} \\in \\mathbb{R}^m\\\\), and \\\\(\\boldsymbol{f}: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n\\\\), and \\\\(\\boldsymbol{g}: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n \\times \\mathbb{R}^m\\\\) are locally Lipschitz functions, with continuity on \\\\(\\mathbb{R}^n\\\\). For a Lipschitz continuous state feedback \\\\(\\boldsymbol{k}: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\\\), we can write the closed-loop system dynamics as\n",
    "\n",
    "\\begin{align}\n",
    "    \\dot{\\boldsymbol{x}} = \\boldsymbol{f}_{cl} \\triangleq \\boldsymbol{f}(\\boldsymbol{x}) + \\boldsymbol{g}(\\boldsymbol{x})\\boldsymbol{k}(\\boldsymbol{x}).\n",
    "    \\label{eq:cbf::closed_loop}\n",
    "\\end{align}\n",
    "\n",
    "whereupon the locally Lipschitz continuous property  of \\\\(\\boldsymbol{f}, \\boldsymbol{g} \\\\), and  \\\\(\\boldsymbol{k}\\\\) implies that \\\\( \\boldsymbol{f}_{cl} \\\\) takes the local Lipzchitz continuity property. Thus, for any initial condition \\\\(\\boldsymbol{x}_0: \\boldsymbol{x}(0) \\in \\mathbb{R}^n\\\\), we must have a maximum time interval \\\\(I(\\boldsymbol{x}_0) = [0, t_{max})\\\\)  such that \\\\(\\boldsymbol{x}(t)\\\\) is the solution of \\eqref{eq:cbf::closed_loop} on \\\\(I(\\boldsymbol{x}(0))\\\\). Here, \\\\(\\boldsymbol{f}_{cl}\\\\) is forward complete, $t_{max} = \\infty$.\n",
    "\n",
    "\n",
    "<a name=\"Invariance\"></a>\n",
    "#### **Safe Sets, and Invariance**\n",
    "\n",
    "Safety with CBFs are in general realized with the notion of safe sets within the state space that the system must remain in order for it to be considered safe.\n",
    "\n",
    "We define a zero-superlevel set \\\\(\\mathcal{C} \\subset \\mathbb{R}^n\\\\) of a continuously differentiable function \\\\(h: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\\\), i.e.\n",
    "\n",
    "\\begin{align}\n",
    "  \\mathcal{C} = \\{ \\boldsymbol{x} \\in \\mathbb{R}^n: h(x) \\ge 0 \\},\n",
    "\\end{align}\n",
    "\n",
    "such that on the boundary of the superlevel set, $\\partial \\mathcal{C} \\triangleq \\{ \\boldsymbol{x} \\in \\mathbb{R}^n: h(x) = 0 \\}$; and in the interior of the \\\\(0\\\\)-superlevel set, we have $Int (\\mathcal{C}) \\triangleq \\{ \\boldsymbol{x} \\in \\mathbb{R}^n: h(x) > 0 \\}$. It is generally assumed that $\\mathcal{C}$ is nonempty (\\i.e. $\\mathcal{C} \\neq \\emptyset$) and it contains no isolated points, (i.e. $Int (\\mathcal{C}) = \\mathcal{C}$).  **\\\\(\\mathcal{C}\\\\) defines the safe set.** Let us now define the concept of forward invariance and safety.\n",
    "\n",
    "<a name=\"safety\"></a>\n",
    "#### **Forward Invariance and Safety**\n",
    "\n",
    "A set \\\\(\\mathcal{C} \\subset \\mathbb{R}^n \\\\) is said to be **forward invariant** if for every \\\\(\\boldsymbol{x}_0 \\in \\mathcal{C}\\\\), the solution $\\boldsymbol{x}(t)$ of \\eqref{eq:cbf::closed_loop} satisfies \\\\(\\boldsymbol{x}(t) \\subset \\mathcal{C}\\\\) for all $t \\in I(\\boldsymbol{x_0}$. The system in \\eqref{eq:cbf::closed_loop} is said to be **safe** if it exists on the \\\\(0\\\\)-superlevel set \\\\(\\mathcal{C}\\\\) such that the set \\\\(\\mathcal{C}\\\\) is forward invariant.\n",
    "\n",
    "<a name=\"class-kappa\"></a>\n",
    "#### **Digression: Class \\\\(\\mathcal{K}\\\\) functions**\n",
    "\n",
    "Here, I give a few background definitions that will enable us to define control barrier functions adequately. This [matlab script gist](https://gist.github.com/lakehanne/07333714a3f15ce1728d0ec6225c41a5) describes a few class-\\\\(\\mathcal{K}\\\\) functions that you may find helpful to aid the understanding.\n",
    "\n",
    "+ **Class \\\\(\\mathcal{K}\\\\) Function**: Supose we have a continuous function \\\\(\\alpha: [0, a) \\rightarrow \\mathbb{R}\\_+\\\\), where \\\\(a>0\\\\), we say \\\\(\\alpha\\\\) is a **_class \\\\(\\mathcal{K}\\\\) (\\\\(\\alpha \\in \\mathcal{K}\\\\))_** function if \\\\(\\alpha(0) = 0\\\\) and \\\\(\\alpha\\\\) is strictly monotonically increasing.\n",
    "\n",
    "+ **Class \\\\(\\mathcal{K}_\\infty\\\\) Function**: Supose we have a continuous function \\\\(\\alpha: [0, a) \\rightarrow \\mathbb{R}\\_+, a = \\infty\\\\), we say \\\\(\\alpha\\\\) is a **_class \\\\(\\mathcal{K}_\\infty \\, (\\alpha \\in \\mathcal{K}_\\infty\\\\))_** function if \\\\(\\alpha(0) = 0\\\\) and \\\\(\\lim\\_{r\\rightarrow \\infty}\\alpha(r)=\\infty\\\\) is strictly monotonically increasing.\n",
    "\n",
    "+ **Class \\\\(\\mathcal{KL}\\\\) Function**: Supose we have a continuous function \\\\(\\beta: [0, a) \\times [0, \\infty) \\rightarrow [0, \\infty) \\\\), we say \\\\(\\beta\\\\) is **_class \\\\(\\mathcal{KL} \\\\)_** if for each fixed \\\\(s\\\\), the mapping \\\\(\\beta(r, s)\\\\) belongs to class \\\\(\\mathcal{K}\\\\) with respect to \\\\(r\\\\) and, for each fixed \\\\(r\\\\), the mapping \\\\(\\beta(r, s)\\\\)  is decreasing with respect to \\\\(s\\\\) and \\\\(\\beta(r,s)\\rightarrow 0\\\\) as \\\\(s\\rightarrow\\infty\\\\).\n",
    "\n",
    "+ **Extended class \\\\(\\mathcal{K}\\\\) Function**: A continuous function \\\\(\\alpha: (-b, a) \\rightarrow \\mathbb{R} \\\\) with \\\\(a, b > 0\\\\), belongs to the _**extended class**_ \\\\(\\mathcal{K}\\\\) (\\\\(\\alpha \\in \\mathcal{K}_e\\\\) ) if \\\\(\\alpha(0) = 0\\\\) and \\\\(\\alpha\\\\) is strictly monotonically increasing.\n",
    "\n",
    "+ **Extended class \\\\(\\mathcal{K}_\\infty\\\\) Function**: If \\\\(a, b = \\infty, \\, \\lim\\_{r\\rightarrow -\\infty} \\alpha(r) = -\\infty\\\\),  and \\\\(\\lim_{r\\rightarrow \\infty} \\alpha(r) = \\infty \\\\), then \\\\(\\alpha\\\\)  is said to belong to an _**extended class**_  \\\\(\\mathcal{K}_\\infty (\\alpha \\in  \\mathcal{K}_{\\infty, e}). \\\\)\n",
    "\n",
    "#### **Control Barrier Functions: A Definition**\n",
    "\n",
    "Now that we have an understanding of the prerequisites, we can give a statement that describes CBFs.\n",
    "\n",
    "Suppose that \\\\(\\mathcal{C} \\subset \\mathbb{R}^n\\\\) is a \\\\(0\\\\)-superlevel set of a continuously differentiable function \\\\(h: \\mathbb{R}^n \\rightarrow \\mathbb{R} \\\\) with \\\\(0\\\\) a regular value. The function \\\\(h\\\\) is a **control barrier function** for \\eqref{eq:cbfs::control_affine} on the superlevel set \\\\(\\mathcal{C}\\\\) if there exists \\\\(\\alpha \\in \\mathcal{K}_{\\infty,e}\\\\) such that for all \\\\(\\boldsymbol{x} \\in \\mathbb{R}^n\\\\), we have\n",
    "\n",
    "\\begin{align}\n",
    "  \\sup_{\\boldsymbol{u} \\in \\mathbb{R}^m} \\dot{h}(\\boldsymbol{x}, \\boldsymbol{u}) \\triangleq \\nabla h(\\boldsymbol{x}) \\boldsymbol{\\dot{x}} \\equiv \\nabla h(\\boldsymbol{x}) (\\boldsymbol{f}(\\boldsymbol{x}) + \\boldsymbol{g}(\\boldsymbol{x}))\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "  &= \\boldsymbol{L_f} h(\\boldsymbol(x)) + \\boldsymbol{L_g} h(\\boldsymbol(x)) \\boldsymbol{u} \\ge -\\alpha(h(\\boldsymbol{x}))\n",
    "  %\n",
    "  \\label{eq:cbfs::cbf-def}\n",
    "\\end{align}\n",
    "\n",
    "with \\\\(\\boldsymbol{L_f} h(\\boldsymbol(x))\\\\) and \\\\(\\boldsymbol{L_g} h(\\boldsymbol(x))\\\\) being [Lie derivatives](https://en.wikipedia.org/wiki/Lie_derivative).\n",
    "\n",
    "It follows that for a CBF \\\\(h\\\\) for system \\eqref{eq:cbfs::control_affine} and an \\\\(\\alpha \\in \\mathcal{K}_{\\infty, e}\\\\), the point-wise set of all control values that satisfies \\eqref{eq:cbfs::cbf-def} is given by,\n",
    "\n",
    "\\begin{align}\n",
    "  K_{cbf}(\\boldsymbol{x}) \\triangleq \\{ \\boldsymbol{u} \\in \\mathbb{R}^m  | \\dot{h}(\\boldsymbol{x, u}) \\ge -\\alpha(h(\\boldsymbol{x}))\n",
    "  \\}.\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67db429-d282-4b1d-aebf-e67ed99b7dce",
   "metadata": {},
   "source": [
    "# Recent Literatures\n",
    "## Control-Barrier Functions (CBFs)\n",
    "### Learning-based CBFs (SOS, QP, Optimization and and RL-based)\n",
    "\n",
    "•\tX. Xu, J. W. Grizzle, P. Tabuada, and A. D. Ames. Correctness guarantees for the composition of lane keeping and adaptive cruise control. IEEE Transactions on Automation Science and Engineering, 15(3):1216–1229, 2017.\n",
    " \n",
    "•\tR. Cheng, G. Orosz, R. M. Murray, and J. W. Burdick. End-to-end safe reinforcement learning through barrier functions for safety-critical continuous control tasks. In The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, pages 3387–3395, 2019. doi: 10.1609/aaai. 408 v33i01.33013387. URL https://doi.org/10.1609/aaai.v33i01.33013387.\n",
    "\n",
    "•\tR. Cheng, A. Verma, G. Orosz, S. Chaudhuri, Y. Yue, and J. Burdick. Control regularization 410 for reduced variance reinforcement learning. In K. Chaudhuri and R. Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pages 1141–1150. PMLR, 2019. URL http://proceedings.mlr.press/v97/cheng19a.html.\n",
    "\n",
    "•\tL. Wang, D. Han, and M. Egerstedt. Permissive barrier certificates for safe stabilization using sum-of-squares. In 2018 Annual American Control Conference (ACC), pages 585–590. IEEE, 2018\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52a2902-6bc1-4bbb-81a1-2ffadab92a79",
   "metadata": {},
   "source": [
    "\n",
    "Learning Nonlinear Dynamics (and/or Control)\n",
    "============================\n",
    "\n",
    "+   Khansari-Zadeh, S. Mohammad, and Aude Billard. \"[Learning stable nonlinear dynamical systems with gaussian mixture models](https://scholar.google.com/scholar_url?url=https://ieeexplore.ieee.org/iel5/8860/6032150/05953529.pdf%3Fcasa_token%3Dge1pR0WHSE0AAAAA:CPQgf-vkxbqXpEP05SVqKVXek5aDRMiN6YSpiOr-lbO38-9GzKGMd5R4pZE6TtIoskJSv_WVvwo&hl=en&sa=T&oi=gsb-gga&ct=res&cd=0&d=15360571889057521224&ei=3dvxYNqyGf2Ly9YPs4SHsAg&scisig=AAGBfm26IQasO44AKrl1FFk0OFgNbcKsxg)\". IEEE Transactions on Robotics 27, no. 5 (2011): 943-957.\n",
    "\n",
    "+   Ya-Chien Chang, Nima Roohi, and Sicun Gao. [Neural Lyapunov control](https://arxiv.org/pdf/2005.00611). In Advances in Neural  Information Processing Systems, 2019.\n",
    "\n",
    "+   J Zico Kolter and Gaurav Manek. [Learning stable deep dynamics models](https://arxiv.org/pdf/2001.06116.pdf). In Advances in\n",
    "Neural Information Processing Systems, pages 11126–11134, 2019.\n",
    "\n",
    "+   Spencer M Richards, Felix Berkenkamp, and Andreas Krause. [The Lyapunov neural network: Adaptive stability certification for safe learning of dynamical systems](http://proceedings.mlr.press/v87/richards18a/richards18a.pdf). arXiv preprint arXiv:1808.00924, 2018.\n",
    "\n",
    "+   Yinlam Chow, Ofir Nachum, Edgar Duenez-Guzman, and Mohammad Ghavamzadeh. [A\n",
    "Lyapunov-based approach to safe reinforcement learning](https://scholar.google.com/scholar_url?url=https://arxiv.org/pdf/1805.07708&hl=en&sa=T&oi=gsb-gga&ct=res&cd=0&d=11292083648863613816&ei=jtzxYNjBFYjwmAGO1J-oCw&scisig=AAGBfm1Tb4aaNv8X8z-JQue_ffP4gCvSHg). In Advances in Neural Information\n",
    "Processing Systems, pages 8092–8101, 2018.\n",
    "\n",
    "<!--+   Stanley: The Robot that Won the DARPA Grand Challenge: https://onlinelibrary.wiley.com/doi/epdf/10.1002/rob.20147-->\n",
    "\n",
    "+   Schaal, Stefan, Christopher G. Atkeson, and Sethu Vijayakumar. \"[Scalable techniques from nonparametric statistics for real time robot learning](https://roland.pri.ee/doktor/papers/LWL/LWPRreference.pdf).\" Applied Intelligence 17, no. 1 (2002): 49-60.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5122d6d3-9cd0-43e7-9470-d33edfce2f31",
   "metadata": {},
   "source": [
    "## General techniques in vogue for certifying robustness of neural network policies\n",
    "\n",
    "These procedures basically bind the Lie derivatives of learned neural barrier function around sampled states along vehicle flow dynmics.\n",
    "\n",
    "•\tWeng, Lily, Pin-Yu Chen, Lam Nguyen, Mark Squillante, Akhilan Boopathy, Ivan Oseledets, and Luca Daniel. \"[PROVEN: Verifying robustness of neural networks with a probabilistic approach](http://proceedings.mlr.press/v97/weng19a/weng19a.pdf).\" In International Conference on Machine Learning, pp. 6727-6736. PMLR, 2019.\n",
    "\n",
    "•\tT.-W. Weng, H. Zhang, H. Chen, Z. Song, C.-J. Hsieh, D. Boning, I. S. Dhillon, and L. Daniel. [Towards fast computation of certified robustness for relu networks](http://proceedings.mlr.press/v80/weng18a/weng18a.pdf). ICML, 2018.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa5202-750d-4151-bf35-66c140b878d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
